document.addEventListener("DOMContentLoaded", () => {
  const micBtn = document.getElementById("micBtn");
  const micIcon = document.getElementById("micIcon");
  const sphere = document.getElementById("sphere");

  const micOnSVG = "icon/mic-mute.svg";
  const micOffSVG = "icon/mic.svg";

  let audioCtx, analyser, dataArray, source, mediaStream;
  let recognition = null;
  let listening = false;
  let baseSize = parseInt(window.getComputedStyle(sphere).width);
  let silenceTimer = null;
  let thinking = false;

  // --- userAgent Ð»Ð¾Ð³ ---
  const ua = navigator.userAgent;
  console.log("UserAgent:", ua);
  alert("UA:\n" + ua.substring(0, 180) + (ua.length > 180 ? "..." : ""));

  // --- SpeechRecognition ---
  if ("webkitSpeechRecognition" in window || "SpeechRecognition" in window) {
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.lang = "ru-RU";
    recognition.interimResults = false;
    recognition.continuous = false;
    console.log("SpeechRecognition ÑÐ¾Ð·Ð´Ð°Ð½");
  } else {
    console.warn("Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ");
  }

  // === ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ½Ð¾Ð¿ÐºÐ¸ ===
  micBtn.addEventListener("click", async () => {
    if (listening) {
      stopAll("manual stop");
      return;
    }

    console.log("â–¶ ÐÐ°Ð¶Ð°Ñ‚Ð° ÐºÐ½Ð¾Ð¿ÐºÐ°, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½...");
    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("âœ… getUserMedia ÑƒÑÐ¿ÐµÑˆÐ½Ð¾");

      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      if (audioCtx.state === "suspended") await audioCtx.resume();

      source = audioCtx.createMediaStreamSource(mediaStream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      dataArray = new Uint8Array(analyser.frequencyBinCount);
      source.connect(analyser);

      listening = true;
      micIcon.src = micOnSVG;
      visualizeAudio();
      startRecognition();
      startSilenceTimer();
    } catch (err) {
      console.error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ðµ Ðº Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ñƒ:", err);
      alert("ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ñƒ: " + err.message);
    }
  });

  // === Ð—Ð°Ð¿ÑƒÑÐº Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ ===
  function startRecognition() {
    if (!recognition) {
      console.warn("ÐÐµÑ‚ SpeechRecognition â€” Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹.");
      return;
    }

    try {
      recognition.start();
      console.log("ðŸŸ¢ SpeechRecognition start()");
    } catch (err) {
      console.error("SpeechRecognition start() error:", err);
    }

    recognition.onresult = async (event) => {
      console.log("ðŸŽ¤ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾:", event.results[0][0].transcript);
      const text = event.results[0][0].transcript;
      stopAll("got result");

      thinking = true;
      showThinkingAnimation();

      try {
        const res = await fetch("/api/sendMessage", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text, voice: "oksana" }),
        });
        const data = await res.json();
        thinking = false;

        if (data.audio) {
          const audio = new Audio("data:audio/mp3;base64," + data.audio);
          audio.play();
          audio.onended = resetSphere;
        } else {
          resetSphere();
        }
      } catch (e) {
        console.error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸:", e);
        resetSphere();
      }
    };

    recognition.onerror = (e) => {
      console.error("SpeechRecognition error:", e.error);
      stopAll("error");
    };

    recognition.onend = () => {
      console.log("ðŸ”´ SpeechRecognition onend()");
      stopAll("onend");
    };
  }

  // === ÐÐ½Ð¸Ð¼Ð°Ñ†Ð¸Ñ ÑÑ„ÐµÑ€Ñ‹ ===
  function visualizeAudio() {
    if (!listening || !analyser) return;
    requestAnimationFrame(visualizeAudio);

    analyser.getByteFrequencyData(dataArray);
    const avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

    const size = baseSize + avg / 2;
    sphere.style.width = size + "px";
    sphere.style.height = size + "px";
    const lightness = Math.min(70, 50 + avg / 3);
    sphere.style.backgroundColor = `hsl(120,70%,${lightness}%)`;
  }

  function showThinkingAnimation() {
    sphere.classList.add("thinking");
    sphere.style.backgroundColor = "rgb(5,229,203)";
  }

  function resetSphere() {
    sphere.classList.remove("thinking");
    sphere.style.width = baseSize + "px";
    sphere.style.height = baseSize + "px";
    sphere.style.backgroundColor = "rgb(17,250,83)";
  }

  // === Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸Ñ (ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ Ñ€ÐµÑ‡Ð¸ 5 ÑÐµÐº â€” ÑÑ‚Ð¾Ð¿) ===
  function startSilenceTimer() {
    clearTimeout(silenceTimer);
    silenceTimer = setTimeout(() => {
      console.log("â¹ ÐÐµÑ‚ Ð·Ð²ÑƒÐºÐ° 5 ÑÐµÐº â€” Ð°Ð²Ñ‚Ð¾ ÑÑ‚Ð¾Ð¿.");
      stopAll("silence timeout");
    }, 5000);
  }

  function stopAll(reason = "") {
    console.log("â›” stopAll()", reason);
    clearTimeout(silenceTimer);

    if (recognition) {
      try {
        recognition.stop();
      } catch {}
    }
    if (mediaStream) {
      mediaStream.getTracks().forEach((t) => t.stop());
    }
    listening = false;
    micIcon.src = micOffSVG;
    resetSphere();
  }
});
